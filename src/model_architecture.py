import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.regularizers import l2

def creer_modele_cnn(forme_entree=(100, 100, 3), nb_classes=5, taux_dropout=0.5):
    """
    Cr√©e un mod√®le de r√©seau de neurones convolutif (CNN) pour la classification de fruits.

    Pourquoi cette architecture ?
    - Simple : s'entra√Æne rapidement sur un GPU gratuit (Colab)
    - Profonde : d√©tecte efficacement les caract√©ristiques visuelles des fruits
    - Moderne : int√®gre Dropout, r√©gularisation L2, et bonnes pratiques

    Arguments :
        forme_entree (tuple) : dimensions des images d'entr√©e (hauteur, largeur, canaux)
        nb_classes (int) : nombre de classes √† pr√©dire
        taux_dropout (float) : pourcentage de neurones d√©sactiv√©s pendant l'entra√Ænement

    Retour :
        Un mod√®le Keras compil√©, pr√™t √† √™tre entra√Æn√©
    """

    modele = models.Sequential([
        
        # Couche d'entr√©e
        layers.Input(shape=forme_entree, name='images_entree'),

        # Bloc convolutionnel 1
        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv2d_1'),
        layers.MaxPooling2D(pool_size=(2, 2), name='maxpool_1'),
        layers.Dropout(taux_dropout * 0.5, name='dropout_1'),  # Dropout l√©ger en d√©but de r√©seau

        # Bloc convolutionnel 2
        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2d_2'),
        layers.MaxPooling2D(pool_size=(2, 2), name='maxpool_2'),
        layers.Dropout(taux_dropout * 0.5, name='dropout_2'),

        # Bloc convolutionnel 3
        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2d_3'),
        layers.MaxPooling2D(pool_size=(2, 2), name='maxpool_3'),
        layers.Dropout(taux_dropout * 0.75, name='dropout_3'),  # Dropout plus fort en fin de r√©seau

        # Aplatissement de la sortie convolutive
        layers.Flatten(name='flatten'),

        # Couche dense enti√®rement connect√©e
        layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001), name='dense_1'),

        # Dernier Dropout avant la sortie
        layers.Dropout(taux_dropout, name='dropout_final'),

        # Couche de sortie (classification)
        layers.Dense(nb_classes, activation='softmax', name='predictions')
    ])

    return modele


def compiler_modele(modele, taux_apprentissage=0.001):
    """
    Compile le mod√®le avec un optimiseur, une fonction de perte, et des m√©triques.

    Choix :
    - Adam : tr√®s utilis√© pour sa rapidit√© et sa stabilit√©
    - categorical_crossentropy : adapt√©e √† la classification multi-classes avec labels one-hot
    - accuracy et top_2_accuracy : √©valuation utile dans un probl√®me √† 5 classes

    Retour :
        Mod√®le compil√© pr√™t √† l'entra√Ænement
    """

    optimiseur = optimizers.Adam(
        learning_rate=taux_apprentissage,
        beta_1=0.9,
        beta_2=0.999,
        epsilon=1e-07
    )

    modele.compile(
    optimizer=optimiseur,
    loss='categorical_crossentropy',
    metrics=['accuracy']      # ‚Üê GARDEZ SEULEMENT ACCURACY
)

    return modele


def afficher_infos_modele(modele):
    """
    Affiche les informations d√©taill√©es du mod√®le : nombre de param√®tres, m√©moire estim√©e, etc.
    """

    total = modele.count_params()
    entrainables = sum([tf.keras.backend.count_params(w) for w in modele.trainable_weights])
    non_entrainables = total - entrainables
    taille_memoire = total * 4 / (1024 * 1024)

    print(f"üìä Param√®tres totaux       : {total:,}")
    print(f"üîß Param√®tres entra√Ænables : {entrainables:,}")
    print(f"‚ùå Non entra√Ænables        : {non_entrainables:,}")
    print(f"üíæ Taille m√©moire estim√©e  : {taille_memoire:.2f} MB")
    print(f"üìê Forme d'entr√©e          : {modele.input_shape}")
    print(f"üì§ Forme de sortie         : {modele.output_shape}")
    print(f"üî¢ Nombre de couches       : {len(modele.layers)}")


def creer_modele_fruivision():
    """
    Fonction centrale qui cr√©e, compile et affiche les infos du mod√®le Fruivision.
    """

    print("üîß Cr√©ation du mod√®le Fruivision...")

    modele = creer_modele_cnn(
        forme_entree=(100, 100, 3),
        nb_classes=5,
        taux_dropout=0.5
    )

    modele = compiler_modele(modele, taux_apprentissage=0.001)

    afficher_infos_modele(modele)

    return modele


# Test simple du mod√®le
if __name__ == "__main__":
    print("üß™ Test du mod√®le Fruivision...")

    modele = creer_modele_fruivision()
    modele.summary()

    # Test avec une image al√©atoire
    import numpy as np
    print("\nüéØ Pr√©diction test avec une image fictive...")
    faux_input = np.random.random((1, 100, 100, 3))

    try:
        prediction = modele.predict(faux_input, verbose=0)
        print(f"‚úÖ Pr√©diction g√©n√©r√©e avec succ√®s : {prediction[0]}")
        print(f"üèÜ Classe pr√©dite : {np.argmax(prediction[0])}")
    except Exception as e:
        print(f"‚ùå Erreur pendant la pr√©diction : {e}")
